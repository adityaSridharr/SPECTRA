{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (62.5 MB)\n",
      "Collecting glob2\n",
      "  Downloading glob2-0.7.tar.gz (10 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: keras in /home/aditya_sridhar/.local/lib/python3.10/site-packages (3.3.3)\n",
      "Requirement already satisfied: numpy in /home/aditya_sridhar/.local/lib/python3.10/site-packages (1.26.4)\n",
      "Requirement already satisfied: pandas in /home/aditya_sridhar/.local/lib/python3.10/site-packages (1.4.1)\n",
      "Requirement already satisfied: matplotlib in /home/aditya_sridhar/.local/lib/python3.10/site-packages (3.5.1)\n",
      "Requirement already satisfied: scikit-learn in /home/aditya_sridhar/.local/lib/python3.10/site-packages (1.5.2)\n",
      "Requirement already satisfied: absl-py in /home/aditya_sridhar/.local/lib/python3.10/site-packages (from keras) (2.1.0)\n",
      "Requirement already satisfied: namex in /home/aditya_sridhar/.local/lib/python3.10/site-packages (from keras) (0.0.8)\n",
      "Requirement already satisfied: rich in /home/aditya_sridhar/.local/lib/python3.10/site-packages (from keras) (13.7.1)\n",
      "Requirement already satisfied: ml-dtypes in /home/aditya_sridhar/.local/lib/python3.10/site-packages (from keras) (0.3.2)\n",
      "Requirement already satisfied: h5py in /home/aditya_sridhar/.local/lib/python3.10/site-packages (from keras) (3.11.0)\n",
      "Requirement already satisfied: optree in /home/aditya_sridhar/.local/lib/python3.10/site-packages (from keras) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/aditya_sridhar/.local/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/aditya_sridhar/.local/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/aditya_sridhar/.local/lib/python3.10/site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/aditya_sridhar/.local/lib/python3.10/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/aditya_sridhar/.local/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/aditya_sridhar/.local/lib/python3.10/site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/lib/python3/dist-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/aditya_sridhar/.local/lib/python3.10/site-packages (from matplotlib) (4.53.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/aditya_sridhar/.local/lib/python3.10/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/aditya_sridhar/.local/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/aditya_sridhar/.local/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /home/aditya_sridhar/.local/lib/python3.10/site-packages (from optree->keras) (4.12.2)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/aditya_sridhar/.local/lib/python3.10/site-packages (from rich->keras) (2.18.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/aditya_sridhar/.local/lib/python3.10/site-packages (from rich->keras) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/aditya_sridhar/.local/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
      "Building wheels for collected packages: glob2\n",
      "  Building wheel for glob2 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for glob2: filename=glob2-0.7-py2.py3-none-any.whl size=9320 sha256=b8545653cec1baf260730a6560a5bf0336d34ae62f98cd74c71d2d648974d55a\n",
      "  Stored in directory: /home/aditya_sridhar/.cache/pip/wheels/37/07/ce/cbe8d31ad93224571b49fa03f8a5da11cdb31d3845ff73e0f3\n",
      "Successfully built glob2\n",
      "Installing collected packages: glob2, opencv-python\n",
      "Successfully installed glob2-0.7 opencv-python-4.10.0.84\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python glob2 keras numpy pandas matplotlib scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-12 03:02:11.281156: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-12 03:02:12.481789: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-12 03:02:14.929140: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "\n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1) # output size: 16 x 224 x 224\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1) # output size: 32 x 224 x 224\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=3) # output size: 32 x 74 x 74\n",
    "\n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size=3, padding=1) # output size: 32 x 74 x 74\n",
    "        self.conv4 = nn.Conv2d(32, 64, kernel_size=3, padding=1)    # output size: 64 x 74 x 74\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=3) # output size: 64 x 24 x 24\n",
    "\n",
    "        self.conv5 = nn.Conv2d(64, 128, kernel_size=3, padding=1)   # output size: 128 x 24 x 24\n",
    "        self.conv6 = nn.Conv2d(128, 256, kernel_size=3, padding=1) # output size: 256 x 24 x 24\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=3) # output size: 256 x 8 x 8\n",
    "\n",
    "        # Batch normalization\n",
    "        self.batch_norm = nn.BatchNorm2d(256)\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(256 * 2 * 2, 512)\n",
    "        self.fc2 = nn.Linear(512, 201)  # Output size is 201 (number of classes)\n",
    "        \n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convolutions and pooling\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = F.relu(self.conv6(x))\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        # Batch normalization\n",
    "        x = self.batch_norm(x)\n",
    "\n",
    "        # Flatten and fully connected layers\n",
    "        x = x.view(x.size(0), -1)  # Flatten the output\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)  # This should output a vector of length 201\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/es21btech11007/xml/CUB_200_2011/classes.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m labels_dict \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/home/es21btech11007/xml/CUB_200_2011/classes.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m f:\n\u001b[1;32m      5\u001b[0m         v, k \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Split on the first space\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/es21btech11007/xml/CUB_200_2011/classes.txt'"
     ]
    }
   ],
   "source": [
    "labels_dict = {}\n",
    "\n",
    "with open('/home/es21btech11007/xml/CUB_200_2011/classes.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        v, k = line.split(' ', 1)  # Split on the first space\n",
    "        labels_dict[k.strip()] = int(v.strip())\n",
    "\n",
    "labels_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    images = []\n",
    "    labels = []\n",
    "    size = (64, 64)\n",
    "    data_path = '/home/es21btech11007/xml/CUB_200_2011/images'\n",
    "    \n",
    "    print('Loading Data from File...', end='')\n",
    "    for folder in os.listdir(data_path):\n",
    "        fol = folder.strip('._')\n",
    "        \n",
    "        # Check if folder is in the labels_dict\n",
    "        if fol in labels_dict:\n",
    "            path = os.path.join(data_path, fol)\n",
    "            print(f\"Processing folder: {fol}\", end='|')\n",
    "            for image in os.listdir(path):\n",
    "                try:\n",
    "                    temp_img = cv2.imread(os.path.join(path, image))\n",
    "                    temp_img = cv2.resize(temp_img, size, interpolation=cv2.INTER_AREA)\n",
    "                    images.append(temp_img)\n",
    "                    labels.append(labels_dict[fol])\n",
    "                    \n",
    "                    # Data augmentation (flipping the image)\n",
    "                    temp_img = cv2.flip(temp_img, flipCode=1)\n",
    "                    images.append(temp_img)\n",
    "                    labels.append(labels_dict[fol])\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {image}: {e}\")\n",
    "        else:\n",
    "            print(f\"Folder {fol} not found in labels_dict\")\n",
    "    \n",
    "    # Check if images and labels lists are not empty\n",
    "    if not images or not labels:\n",
    "        print(f\"Error: No images or labels found. Images length: {len(images)}, Labels length: {len(labels)}\")\n",
    "        return None, None, None, None\n",
    "\n",
    "    images = np.array(images)\n",
    "    images = images.astype('float32') / 255.0\n",
    "    labels = np.array(labels)  # Leave as integer class indices\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2)\n",
    "    print(f'\\nLoaded {len(X_train)} images for training, Train data shape: {X_train.shape}')\n",
    "    print(f'Loaded {len(X_test)} images for testing, Test data shape: {X_test.shape}')\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data from File...Processing folder: 001.Black_footed_Albatross|Processing folder: 002.Laysan_Albatross|Processing folder: 003.Sooty_Albatross|Processing folder: 004.Groove_billed_Ani|Processing folder: 005.Crested_Auklet|Processing folder: 006.Least_Auklet|Processing folder: 007.Parakeet_Auklet|Processing folder: 008.Rhinoceros_Auklet|Processing folder: 009.Brewer_Blackbird|Processing folder: 010.Red_winged_Blackbird|Processing folder: 011.Rusty_Blackbird|Processing folder: 012.Yellow_headed_Blackbird|Processing folder: 013.Bobolink|Processing folder: 014.Indigo_Bunting|Processing folder: 015.Lazuli_Bunting|Processing folder: 016.Painted_Bunting|Processing folder: 017.Cardinal|Processing folder: 018.Spotted_Catbird|Processing folder: 019.Gray_Catbird|Processing folder: 020.Yellow_breasted_Chat|Processing folder: 021.Eastern_Towhee|Processing folder: 022.Chuck_will_Widow|Processing folder: 023.Brandt_Cormorant|Processing folder: 024.Red_faced_Cormorant|Processing folder: 025.Pelagic_Cormorant|Processing folder: 026.Bronzed_Cowbird|Processing folder: 027.Shiny_Cowbird|Processing folder: 028.Brown_Creeper|Processing folder: 029.American_Crow|Processing folder: 030.Fish_Crow|Processing folder: 031.Black_billed_Cuckoo|Processing folder: 032.Mangrove_Cuckoo|Processing folder: 033.Yellow_billed_Cuckoo|Processing folder: 034.Gray_crowned_Rosy_Finch|Processing folder: 035.Purple_Finch|Processing folder: 036.Northern_Flicker|Processing folder: 037.Acadian_Flycatcher|Processing folder: 038.Great_Crested_Flycatcher|Processing folder: 039.Least_Flycatcher|Processing folder: 040.Olive_sided_Flycatcher|Processing folder: 041.Scissor_tailed_Flycatcher|Processing folder: 042.Vermilion_Flycatcher|Processing folder: 043.Yellow_bellied_Flycatcher|Processing folder: 044.Frigatebird|Processing folder: 045.Northern_Fulmar|Processing folder: 046.Gadwall|Processing folder: 047.American_Goldfinch|Processing folder: 048.European_Goldfinch|Processing folder: 049.Boat_tailed_Grackle|Processing folder: 050.Eared_Grebe|Processing folder: 051.Horned_Grebe|Processing folder: 052.Pied_billed_Grebe|Processing folder: 053.Western_Grebe|Processing folder: 054.Blue_Grosbeak|Processing folder: 055.Evening_Grosbeak|Processing folder: 056.Pine_Grosbeak|Processing folder: 057.Rose_breasted_Grosbeak|Processing folder: 058.Pigeon_Guillemot|Processing folder: 059.California_Gull|Processing folder: 060.Glaucous_winged_Gull|Processing folder: 061.Heermann_Gull|Processing folder: 062.Herring_Gull|Processing folder: 063.Ivory_Gull|Processing folder: 064.Ring_billed_Gull|Processing folder: 065.Slaty_backed_Gull|Processing folder: 066.Western_Gull|Processing folder: 067.Anna_Hummingbird|Processing folder: 068.Ruby_throated_Hummingbird|Processing folder: 069.Rufous_Hummingbird|Processing folder: 070.Green_Violetear|Processing folder: 071.Long_tailed_Jaeger|Processing folder: 072.Pomarine_Jaeger|Processing folder: 073.Blue_Jay|Processing folder: 074.Florida_Jay|Processing folder: 075.Green_Jay|Processing folder: 076.Dark_eyed_Junco|Processing folder: 077.Tropical_Kingbird|Processing folder: 078.Gray_Kingbird|Processing folder: 079.Belted_Kingfisher|Processing folder: 080.Green_Kingfisher|Processing folder: 081.Pied_Kingfisher|Processing folder: 082.Ringed_Kingfisher|Processing folder: 083.White_breasted_Kingfisher|Processing folder: 084.Red_legged_Kittiwake|Processing folder: 085.Horned_Lark|Processing folder: 086.Pacific_Loon|Processing folder: 087.Mallard|Processing folder: 088.Western_Meadowlark|Processing folder: 089.Hooded_Merganser|Processing folder: 090.Red_breasted_Merganser|Processing folder: 091.Mockingbird|Processing folder: 092.Nighthawk|Processing folder: 093.Clark_Nutcracker|Processing folder: 094.White_breasted_Nuthatch|Processing folder: 095.Baltimore_Oriole|Processing folder: 096.Hooded_Oriole|Processing folder: 097.Orchard_Oriole|Processing folder: 098.Scott_Oriole|Processing folder: 099.Ovenbird|Processing folder: 100.Brown_Pelican|Processing folder: 101.White_Pelican|Processing folder: 102.Western_Wood_Pewee|Processing folder: 103.Sayornis|Processing folder: 104.American_Pipit|Processing folder: 105.Whip_poor_Will|Processing folder: 106.Horned_Puffin|Processing folder: 107.Common_Raven|Processing folder: 108.White_necked_Raven|Processing folder: 109.American_Redstart|Processing folder: 110.Geococcyx|Processing folder: 111.Loggerhead_Shrike|Processing folder: 112.Great_Grey_Shrike|Processing folder: 113.Baird_Sparrow|Processing folder: 114.Black_throated_Sparrow|Processing folder: 115.Brewer_Sparrow|Processing folder: 116.Chipping_Sparrow|Processing folder: 117.Clay_colored_Sparrow|Processing folder: 118.House_Sparrow|Processing folder: 119.Field_Sparrow|Processing folder: 120.Fox_Sparrow|Processing folder: 121.Grasshopper_Sparrow|Processing folder: 122.Harris_Sparrow|Processing folder: 123.Henslow_Sparrow|Processing folder: 124.Le_Conte_Sparrow|Processing folder: 125.Lincoln_Sparrow|Processing folder: 126.Nelson_Sharp_tailed_Sparrow|Processing folder: 127.Savannah_Sparrow|Processing folder: 128.Seaside_Sparrow|Processing folder: 129.Song_Sparrow|Processing folder: 130.Tree_Sparrow|Processing folder: 131.Vesper_Sparrow|Processing folder: 132.White_crowned_Sparrow|Processing folder: 133.White_throated_Sparrow|Processing folder: 134.Cape_Glossy_Starling|Processing folder: 135.Bank_Swallow|Processing folder: 136.Barn_Swallow|Processing folder: 137.Cliff_Swallow|Processing folder: 138.Tree_Swallow|Processing folder: 139.Scarlet_Tanager|Processing folder: 140.Summer_Tanager|Processing folder: 141.Artic_Tern|Processing folder: 142.Black_Tern|Processing folder: 143.Caspian_Tern|Processing folder: 144.Common_Tern|Processing folder: 145.Elegant_Tern|Processing folder: 146.Forsters_Tern|Processing folder: 147.Least_Tern|Processing folder: 148.Green_tailed_Towhee|Processing folder: 149.Brown_Thrasher|Processing folder: 150.Sage_Thrasher|Processing folder: 151.Black_capped_Vireo|Processing folder: 152.Blue_headed_Vireo|Processing folder: 153.Philadelphia_Vireo|Processing folder: 154.Red_eyed_Vireo|Processing folder: 155.Warbling_Vireo|Processing folder: 156.White_eyed_Vireo|Processing folder: 157.Yellow_throated_Vireo|Processing folder: 158.Bay_breasted_Warbler|Processing folder: 159.Black_and_white_Warbler|Processing folder: 160.Black_throated_Blue_Warbler|Processing folder: 161.Blue_winged_Warbler|Processing folder: 162.Canada_Warbler|Processing folder: 163.Cape_May_Warbler|Processing folder: 164.Cerulean_Warbler|Processing folder: 165.Chestnut_sided_Warbler|Processing folder: 166.Golden_winged_Warbler|Processing folder: 167.Hooded_Warbler|Processing folder: 168.Kentucky_Warbler|Processing folder: 169.Magnolia_Warbler|Processing folder: 170.Mourning_Warbler|Processing folder: 171.Myrtle_Warbler|Processing folder: 172.Nashville_Warbler|Processing folder: 173.Orange_crowned_Warbler|Processing folder: 174.Palm_Warbler|Processing folder: 175.Pine_Warbler|Processing folder: 176.Prairie_Warbler|Processing folder: 177.Prothonotary_Warbler|Processing folder: 178.Swainson_Warbler|Processing folder: 179.Tennessee_Warbler|Processing folder: 180.Wilson_Warbler|Processing folder: 181.Worm_eating_Warbler|Processing folder: 182.Yellow_Warbler|Processing folder: 183.Northern_Waterthrush|Processing folder: 184.Louisiana_Waterthrush|Processing folder: 185.Bohemian_Waxwing|Processing folder: 186.Cedar_Waxwing|Processing folder: 187.American_Three_toed_Woodpecker|Processing folder: 188.Pileated_Woodpecker|Processing folder: 189.Red_bellied_Woodpecker|Processing folder: 190.Red_cockaded_Woodpecker|Processing folder: 191.Red_headed_Woodpecker|Processing folder: 192.Downy_Woodpecker|Processing folder: 193.Bewick_Wren|Processing folder: 194.Cactus_Wren|Processing folder: 195.Carolina_Wren|Processing folder: 196.House_Wren|Processing folder: 197.Marsh_Wren|Processing folder: 198.Rock_Wren|Processing folder: 199.Winter_Wren|Processing folder: 200.Common_Yellowthroat|\n",
      "Loaded 18860 images for training, Train data shape: (18860, 64, 64, 3)\n",
      "Loaded 4716 images for testing, Test data shape: (4716, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Train Loss: 5.1206, Train Accuracy: 1.52%\n",
      "Validation Loss: 4.8505, Validation Accuracy: 2.59%\n",
      "\n",
      "Epoch [2/20], Train Loss: 4.5728, Train Accuracy: 4.13%\n",
      "Validation Loss: 4.4157, Validation Accuracy: 5.77%\n",
      "\n",
      "Epoch [3/20], Train Loss: 4.2032, Train Accuracy: 7.80%\n",
      "Validation Loss: 3.9405, Validation Accuracy: 11.20%\n",
      "\n",
      "Epoch [4/20], Train Loss: 3.8681, Train Accuracy: 11.85%\n",
      "Validation Loss: 3.6868, Validation Accuracy: 14.93%\n",
      "\n",
      "Epoch [5/20], Train Loss: 3.5830, Train Accuracy: 16.38%\n",
      "Validation Loss: 3.5636, Validation Accuracy: 16.69%\n",
      "\n",
      "Epoch [6/20], Train Loss: 3.3264, Train Accuracy: 20.28%\n",
      "Validation Loss: 3.2201, Validation Accuracy: 22.01%\n",
      "\n",
      "Epoch [7/20], Train Loss: 3.1197, Train Accuracy: 23.66%\n",
      "Validation Loss: 3.2772, Validation Accuracy: 22.14%\n",
      "\n",
      "Epoch [8/20], Train Loss: 2.8926, Train Accuracy: 27.78%\n",
      "Validation Loss: 3.1018, Validation Accuracy: 25.08%\n",
      "\n",
      "Epoch [9/20], Train Loss: 2.7086, Train Accuracy: 31.21%\n",
      "Validation Loss: 2.9295, Validation Accuracy: 28.05%\n",
      "\n",
      "Epoch [10/20], Train Loss: 2.5364, Train Accuracy: 34.69%\n",
      "Validation Loss: 2.8589, Validation Accuracy: 30.83%\n",
      "\n",
      "Epoch [11/20], Train Loss: 2.3637, Train Accuracy: 38.36%\n",
      "Validation Loss: 2.7902, Validation Accuracy: 30.58%\n",
      "\n",
      "Epoch [12/20], Train Loss: 2.2071, Train Accuracy: 41.36%\n",
      "Validation Loss: 2.7022, Validation Accuracy: 33.10%\n",
      "\n",
      "Epoch [13/20], Train Loss: 2.0793, Train Accuracy: 43.70%\n",
      "Validation Loss: 2.7202, Validation Accuracy: 32.93%\n",
      "\n",
      "Epoch [14/20], Train Loss: 1.9428, Train Accuracy: 47.18%\n",
      "Validation Loss: 2.6698, Validation Accuracy: 33.99%\n",
      "\n",
      "Epoch [15/20], Train Loss: 1.8026, Train Accuracy: 50.33%\n",
      "Validation Loss: 2.6337, Validation Accuracy: 36.20%\n",
      "\n",
      "Epoch [16/20], Train Loss: 1.6837, Train Accuracy: 52.83%\n",
      "Validation Loss: 2.6498, Validation Accuracy: 36.34%\n",
      "\n",
      "Epoch [17/20], Train Loss: 1.5829, Train Accuracy: 55.39%\n",
      "Validation Loss: 2.7970, Validation Accuracy: 34.35%\n",
      "\n",
      "Epoch [18/20], Train Loss: 1.5023, Train Accuracy: 56.83%\n",
      "Validation Loss: 2.6863, Validation Accuracy: 36.81%\n",
      "\n",
      "Epoch [19/20], Train Loss: 1.3941, Train Accuracy: 59.62%\n",
      "Validation Loss: 2.7078, Validation Accuracy: 36.60%\n",
      "\n",
      "Epoch [20/20], Train Loss: 1.3322, Train Accuracy: 61.26%\n",
      "Validation Loss: 2.6402, Validation Accuracy: 37.77%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_dataset = CustomDataset(X_train, y_train, transform=train_transform)\n",
    "test_dataset = CustomDataset(X_test, y_test, transform=train_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "model = Classifier().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "        \n",
    "        outputs = model(images)  # Forward pass\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()  # Optimization step\n",
    "        \n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    train_loss = running_loss / total\n",
    "    train_accuracy = 100 * correct / total\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%\")\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)  # Forward pass\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            val_loss += loss.item() * images.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    val_loss /= total\n",
    "    val_accuracy = 100 * correct / total\n",
    "    print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\\n\")\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), 'cub_classifier.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
